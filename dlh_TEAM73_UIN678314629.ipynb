{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad5d277-d4e5-4f33-8073-c0836edc76ac",
   "metadata": {},
   "source": [
    "# The Replication and Extension of \"DuETT: Dual Event Time Transformer for Electronic Health Records\"\n",
    "**Team #73 (Solo): Runhua Yang (runhua2@illinois.edu) UIN: 678314629**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db528cf-4b92-426d-abb3-fdf6150644bb",
   "metadata": {},
   "source": [
    "# Summary and Critical Findings (so far)\n",
    "\n",
    "The DuETT model is purported to be the state-of-the-art (SOTA) for the MIMIC-IV 2.0 and PhysioNet-2012 datasets in terms of mortality prediction and phenotype classification tasks. The authors have made the source code for the DuETT model, along with the training and evaluation pipelines for PhysioNet-2012, publicly available. However, due to licensing restrictions, the pipeline for MIMIC-IV 2.0 is not provided, posing challenges for reproducibility. I suspect that licensing concerns may not be the sole reason preventing the publication of the data pipeline code. Additionally, the training and evaluation code for the MIMIC-IV dataset has not been provided, despite the authors' claim of their model's strong generalizability. \n",
    "\n",
    "While the data processing for PhysioNet-2012 is relatively straightforward and standardized, integrating with the torchtime.data library, the situation is less clear for the MIMIC-IV benchmark. The paper's methodology is based on an implementation from MIMIC-III but includes additional features and engineering, which complicates the process of benchmarking. __Based on the sparse information from the paper, a considerable amount of my time was dedicated to developing a data pipeline for MIMIC-IV 2.0, which involved modifying 14 files with 500 lines of code added and 69 lines removed. Furthermore, I worked on the training and evaluation code for MIMIC-IV 2.0, adding 2 files with 386 lines of code.__\n",
    "\n",
    "I deliberately avoided requesting code or details from the authors that were not disclosed initially, focusing instead on determining the true factors influencing the final performance through my own trial runs. A pertinent question arises: Did the authors exert the same level of effort in feature inclusion (85 chart event variables and 29 lab event variables added for ICU mortality) and processing when comparing their model to other approaches, such as XGBoost? Without comprehensive and equivalent feature handling, it becomes difficult to assert that the DuETT model is unequivocally superior to other methodologies. I remain committed to further investigation into this matter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e87136f-e4e3-46f7-bc03-96e7222f4aa1",
   "metadata": {},
   "source": [
    "# Code Repo\n",
    "\n",
    "- Model/Training/Eval: https://github.com/ryuiuc/dlh-model\n",
    "\n",
    "- Data Pipeline: https://github.com/ryuiuc/dlh-data\n",
    "\n",
    "- Link to .ipynb file: https://github.com/ryuiuc/dlh-model/blob/master/dlh_TEAM73_UIN678314629.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f0b63-825d-4013-9c5c-91afe2a506a4",
   "metadata": {},
   "source": [
    "# Paper for Discussion\n",
    "\n",
    "Labach, A., Pokhrel, A., Huang, X.S., Zuberi, S., Yi, S.E., Volkovs, M.,\n",
    "Poutanen, T., & Krishnan, R.G. (2023). **DuETT: Dual Event Time Transformer for\n",
    "Electronic Health Records.** Proceedings of Machine Learning Research, 219:1–26,\n",
    "2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aababaa-e5e8-4c2f-8fdc-e0cc61475f8e",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "## Background of the problem\n",
    "1. What type of problem: The problem addressed in the paper revolves around the effective modeling and analysis of Electronic Health Records (EHR) data for various clinical predictions and insights. Specifically, the paper focuses on the development of a machine learning model capable of handling the unique challenges posed by EHR data, such as high sparsity, irregular observations, and the need to leverage the temporal and event-type dimensions for accurate predictions.\n",
    "\n",
    "2. Importance/Meaning of solving the problem: Solving this problem is crucial for improving patient care and hospital operations. Accurate predictions based on EHR data can lead to timely interventions, reduced readmissions, and better management of healthcare resources. Moreover, understanding the structure and patterns within EHR data can provide valuable insights into patient health trends and inform clinical decision-making processes.\n",
    "\n",
    "3. Difficulty of the problem: The complexity of EHR data, characterized by its high-dimensionality, sparsity, and irregularity, presents significant challenges for traditional time series analysis methods. The need for a model that can effectively capture the relationships between different types of observations and the temporal dynamics of patient health adds to the difficulty.\n",
    "\n",
    "4. State of the art methods and effectiveness: Prior to the proposed method, various neural network models, including recurrent neural networks (RNNs) and gradient boosting models like XGBoost, have been applied to EHR data with varying degrees of success. However, these models often struggle to fully exploit the structured relationships within the data, especially when it comes to multivariate time series with missing values.\n",
    "## Paper explanation\n",
    "1. What did the paper propose: The paper introduces DuETT (Dual Event Time Transformer), a novel architecture that extends the capabilities of Transformers to handle both time and event type dimensions in EHR data. DuETT is designed to provide robust representations from EHR data by transforming sparse time series into a regular sequence with fixed length, thus reducing computational complexity and enabling the use of larger and deeper neural networks.\n",
    "\n",
    "2. Innovations of the method: The key innovations of DuETT include its ability to attend over both time and event type dimensions, the use of self-supervised learning (SSL) for model pre-training, and the design of an input representation that incorporates event information, static variables, and aggregates observations in a way that is computationally efficient. The paper also proposes a novel SSL training scheme that performs masked modeling of measured event values and missingness across both dimensions.\n",
    "\n",
    "3. How well the proposed method works (in its own metrics): The proposed DuETT model outperforms state-of-the-art deep learning models on multiple downstream tasks from the MIMIC-IV and PhysioNet-2012 EHR datasets. It demonstrates superior performance in tasks such as mortality prediction and phenotype classification, showcasing its effectiveness in learning from EHR data.\n",
    "\n",
    "4. Contribution to the research regime: As stated in the paper, the authors believe that their core contributions are:\n",
    "   \n",
    "    (1) the novel DuETT architecture design, which extends Transformers to exploit both time and event modalities of EHR data.\n",
    "\n",
    "    (2) The design of input representation.\n",
    "\n",
    "    (3) A novel self-supervised training scheme that performs masked modelling of measured event values and missingness across both time and event dimensions.\n",
    "\n",
    "    (4) A thorough empirical evaluation of the approach on the MIMIC-IV (Johnson et al., 2022) and PhysioNet-2012 (Silva et al., 2012) hospital EHR datasets, demonstrating state-of-the-art performances (beating XGBoost specifically).\n",
    "NOTE: This paper primarily focuses on the classification and prediction of event values within the modeling framework, not addressing the time-to-event forecasting aspect, which is a popular research topic and application area using similar datasets. Additionally, the scope of this study is restricted to numeric data inputs; it does not capitalize on the potential of textual data and other diverse data modalities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4c9c3-3bbb-4c66-94d8-aa45bd6876bb",
   "metadata": {},
   "source": [
    "# Scope of Reproducibility\n",
    "\n",
    "1. The DuETT model can be sufficiently and accurately replicated to reproduce the original results, thereby validating its effectiveness in handling the complexities of EHR data. The goal is to achieve a comparable level of performance, thereby substantiating its status as state-of-the-art.\n",
    "    Owing to constrained computational resources and time, the following components will be addressed.\n",
    "    - MIMIC-IV 2.0 ICU Mortality Task\n",
    "    - PhysioNet-2012 Mortaliy\n",
    "    - Excluding:\n",
    "        - MIMIC-IV ED Transfer to ICU task\n",
    "        - MIMIC-IV ICU Phenotyping\n",
    "          \n",
    "3. The outcomes of the ablation study should correspond with the findings\n",
    "reported in the paper. Ablations to be covered (progressing, till end of project):\n",
    "    - Attention Mechanisms: Due to limitations in time and resources, this project will focus on replicating the \"Time Transformer only\" experiment, which\n",
    "experienced the most significant decrease in performance.\n",
    "    - Self-Supervised Learning: Due to limitations in time and resources, this project will focus on replicating the \"Event type masking only\" experiment, which experienced the most significant decrease in performance. Note: This suggests that there is potential for enhancing the current masking approach, particularly along the time dimension, which could lead to a boost in the model's overall performance.\n",
    "    - The remaining ablation studies presented in the paper are logical and align with expectations; however, due to constraints in time and resources, they will not be verified as part of this project.\n",
    "   ![](https://uiuc-dlh.s3.amazonaws.com/duett_ablations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b6f7d-c24f-4add-b312-5cd28596cfc0",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b2666-61f9-46c2-87fe-907ac3143c43",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c44d82-274b-4803-980d-17ba77251a78",
   "metadata": {},
   "source": [
    "### MIMIC-IV 2.0 Data:\n",
    "    - Obtain license and download\n",
    "    - Run my below code to pre-process the data and generate input data for ICU Mortality task (Please follow README.md from the below repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95cf2957-8eaa-44ff-9b7e-ba4b0581381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mimic-iv-benchmarks'...\n",
      "remote: Enumerating objects: 396, done.\u001b[K\n",
      "remote: Counting objects: 100% (396/396), done.\u001b[K\n",
      "remote: Compressing objects: 100% (338/338), done.\u001b[K\n",
      "remote: Total 396 (delta 69), reused 366 (delta 53), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (396/396), 27.32 MiB | 22.27 MiB/s, done.\n",
      "Resolving deltas: 100% (69/69), done.\n",
      "Updating files: 100% (73/73), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['GITHUB_TOKEN'] = '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'  # Set this securely, perhaps in a configuration file or environment variable outside of the notebook\n",
    "\n",
    "# Use the token securely without exposing it in the notebook\n",
    "!git clone https://ryuiuc:${GITHUB_TOKEN}@github.com/ryuiuc/dlh-data mimic-iv-benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b41044a-f358-46c1-8213-14c5eb724f7f",
   "metadata": {},
   "source": [
    "**Input Data Pipeline**\n",
    "1. Clone the repo.\n",
    "```\n",
    "       git clone https://github.com/ryuiuc/dlh-data/\n",
    "       cd mimic4-benchmarks/\n",
    "```    \n",
    "2. The following command takes MIMIC-IV CSVs, generates one directory per `SUBJECT_ID` and writes ICU stay information to `data/{SUBJECT_ID}/stays.csv`, diagnoses to `data/{SUBJECT_ID}/diagnoses.csv`, and events to `data/{SUBJECT_ID}/events.csv`. This step might take around an hour.\n",
    "```\n",
    "       python -m mimic4benchmark.scripts.extract_subjects ./mimic-iv data/root/\n",
    "```\n",
    "3. The following command attempts to fix some issues (ICU stay ID is missing) and removes the events that have missing information. About 80% of events remain after removing all suspicious rows (more information can be found in [`mimic4benchmark/scripts/more_on_validating_events.md`](mimic4benchmark/scripts/more_on_validating_events.md)).\n",
    "```\n",
    "       python -m mimic4benchmark.scripts.validate_events data/root/\n",
    "```\n",
    "4. The next command breaks up per-subject data into separate episodes (pertaining to ICU stays). Time series of events are stored in ```{SUBJECT_ID}/episode{#}_timeseries.csv``` (where # counts distinct episodes) while episode-level information (patient age, gender, ethnicity, height, weight) and outcomes (mortality, length of stay, diagnoses) are stores in ```{SUBJECT_ID}/episode{#}.csv```. This script requires two files, one that maps event ITEMIDs to clinical variables and another that defines valid ranges for clinical variables (for detecting outliers, etc.). **Outlier detection is disabled in the current version**.\n",
    "```\n",
    "       python -m mimic4benchmark.scripts.extract_episodes_from_subjects data/root/\n",
    "```\n",
    "5. The next command splits the whole dataset into training and testing sets. Note that the train/test split is the same of all tasks.\n",
    "```\n",
    "       python -m mimic4benchmark.scripts.split_train_and_test data/root/\n",
    "```\n",
    "6. The following commands will generate task-specific datasets, which can later be used in models. These commands are independent, if you are going to work only on one benchmark task, you can run only the corresponding command.\n",
    "```\n",
    "       python -m mimic4benchmark.scripts.create_in_hospital_mortality data/root/ data/in-hospital-mortality/\n",
    "```\n",
    "After the above commands are done, there will be a directory `data/{task}` for in-hospital mortality task.\n",
    "These directories have two sub-directories: `train` and `test`.\n",
    "Each of them contains bunch of ICU stays and one file with name `listfile.csv`, which lists all samples in that particular set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e47a0345-64d4-48fb-8ddb-1abd6072c5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START:\n",
      "\tICUSTAY_IDs: 76943\n",
      "\tHADM_IDs: 69639\n",
      "\tSUBJECT_IDs: 53569\n",
      "REMOVE PATIENTS AGE < 18:\n",
      "\tICUSTAY_IDs: 76943\n",
      "\tHADM_IDs: 69639\n",
      "\tSUBJECT_IDs: 53569\n",
      "FILTER FOR PATIENTS WITH EVENT RECORDS:\n",
      "\tBefore filtering: 76943 stays\n",
      "\tAfter filtering: 76935 stays\n",
      "\tNumber of stays removed: 8\n",
      "FILTER FOR PATIENTS WITH mimic-iv-patient-split.json:\n",
      "\tBefore filtering: 76935 stays\n",
      "\tAfter filtering: 76935 stays\n",
      "\tNumber of stays removed: 0\n",
      "Breaking up stays by subjects: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53569/53569 [06:22<00:00, 140.09it/s]\n",
      "Breaking up diagnoses by subjects: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 53569/53569 [05:28<00:00, 163.16it/s]\n",
      "Processing CHARTEVENTS table: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 329822285/329822285 [55:09<00:00, 99667.55it/s]\n",
      "Processing LABEVENTS table: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 124342638/124342638 [14:57<00:00, 138501.21it/s]\n",
      "Processing OUTPUTEVENTS table: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 4450049/4450049 [02:37<00:00, 28167.29it/s]\n",
      "Namespace(subjects_root_path='data/root/')\n",
      "Iterating over subjects: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53569/53569 [1:33:22<00:00,  9.56it/s]\n",
      "n_events: 398090710\n",
      "empty_hadm: 20622281\n",
      "no_hadm_in_stay: 14128212\n",
      "no_icustay: 475919555\n",
      "recovered: 475919555\n",
      "could_not_recover: 0\n",
      "icustay_missing_in_stays: 0\n",
      "Iterating over subjects: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53573/53573 [2:07:51<00:00,  6.98it/s]\n",
      "train_set length= 45597\n",
      "test_set length= 7972\n",
      "Iterating over patients in test: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 7972/7972 [01:58<00:00, 67.12it/s]\n",
      "Number of created samples: 5547\n",
      "Iterating over patients in train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 45597/45597 [11:40<00:00, 65.11it/s]\n",
      "Number of created samples: 31352\n"
     ]
    }
   ],
   "source": [
    "# cd mimic-iv-benchmarks; run below command line in the terminal. Assuming MIMIC-IV 2.0 data is under mimic-iv/2.0/hosp/\n",
    "# nohup sh -c \"python -m mimic4benchmark.scripts.extract_subjects mimic-iv/2.0/hosp/ data/root/ && python -m mimic4benchmark.scripts.validate_events data/root/ && python -m mimic4benchmark.scripts.extract_episodes_from_subjects data/root/ && python -m mimic4benchmark.scripts.split_train_and_test data/root/ && python -m mimic4benchmark.scripts.create_in_hospital_mortality data/root/ data/in-hospital-mortality/\" > nohup_output.log 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7fc1b60-e243-4844-b0f6-84bc5fbb0ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours,18 Gauge Dressing Occlusive,18 Gauge placed in outside facility,20 Gauge Dressing Occlusive,20 Gauge placed in outside facility,20 Gauge placed in the field,ART BP Diastolic,ART BP Systolic,Admission Weight (lbs.),Alarms On,Ambulatory aid,Anion Gap,Anion gap,Arterial Blood Pressure diastolic,Arterial Blood Pressure systolic,BUN,Base Excess,Bicarbonate,Braden Activity,Braden Friction/Shear,Braden Mobility,Braden Moisture,Braden Nutrition,Braden Sensory Perception,Calcium non-ionized,\"Calcium, Total\",Calculated Total CO2,Capillary Refill L,Capillary Refill R,Chloride,Chloride (serum),Creatinine,Creatinine (serum),Currently experiencing pain,Daily Weight,Dialysis patient,Difficulty swallowing,ETOH,Eye Care,Fraction inspired oxygen,GCS - Eye Opening,GCS - Motor Response,GCS - Verbal Response,GLUCOSE,Gait/Transferring,Glucose (serum),Glucose (whole blood),Glucose (whole blood) (soft),Glucose finger stick (range 70-100),Goal Richmond-RAS Scale,HCO3 (serum),HEMOGLOBIN,Heart Rate,Heart Rate Alarm - Low,Heart rate Alarm - High,Height,Height (cm),Hematocrit,Hematocrit (serum),Hemoglobin,High risk (.51) interventions,History of falling (within 3 mnths),History of slips / falls,Home TF,INR,INR(PT),IV/Saline lock,Insulin pump,Intravenous / IV access prior to admission,Lactate,Lactic Acid,MAGNESIUM,MCH,MCHC,MCV,Magnesium,Manual Blood Pressure Diastolic Left,Manual Blood Pressure Diastolic Right,Manual Blood Pressure Systolic Left,Manual Blood Pressure Systolic Right,Mean blood pressure,Mental status,Non Invasive Blood Pressure diastolic,Non Invasive Blood Pressure mean,Non Invasive Blood Pressure systolic,Non-Invasive Blood Pressure Alarm - High,Non-Invasive Blood Pressure Alarm - Low,O2 Flow,O2 Saturation Pulseoxymetry Alarm - High,O2 Saturation Pulseoxymetry Alarm - Low,O2 saturation pulseoxymetry,Oxygen saturation,PH,PH (Arterial),PH (SOFT),PH (Venous),PH (dipstick),PLATELET COUNT,PT,PTT-CHART,PTT-LAB,Pain Level,Pain Level Response,Parameters Checked,Phosphate,Phosphorous,Platelet Count,Potassium,Potassium (serum),Pressure Ulcer Present,Prothrombin time,RDW,Rate,Red Blood Cells,Resp Alarm - High,Resp Alarm - Low,Respiratory Rate,Respiratory Rate (Total),Respiratory Rate (spontaneous),Richmond-RAS Scale,ST Segment Monitoring On,Secondary diagnosis,Self ADL,Skin Temperature,Sodium,Sodium (serum),SpO2 Desat Limit,Strength L Arm,Strength L Leg,Strength R Arm,Strength R Leg,Temperature,Temperature Fahrenheit,Urea Nitrogen,Visual / hearing deficit,WBC,Weight,White Blood Cells,pCO2,pO2,Age,Gender,English Language,Marital Status,Insurance,Admission Location,Admission Type,Ethnicity,First Care Unit,Observation Window Length\n",
      "0.8411111111111111,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60.0,2.0,1.0,3.0,1.0,4.0,4.0,4.0,9.0,215.07888888888888\n",
      "0.9411111111111111,,,,,,,,178.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60.0,2.0,1.0,3.0,1.0,4.0,4.0,4.0,9.0,215.07888888888888\n",
      "1.3744444444444446,,,,,,,,,,,,,,,,0.0,,,,,,,,,,25.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,38.0,297.0,60.0,2.0,1.0,3.0,1.0,4.0,4.0,4.0,9.0,215.07888888888888\n",
      "1.9577777777777778,,,,,,,,,,,,,,,,0.0,,,,,,,,,,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,36.0,297.0,60.0,2.0,1.0,3.0,1.0,4.0,4.0,4.0,9.0,215.07888888888888\n",
      "2.0077777777777777,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60.0,2.0,1.0,3.0,1.0,4.0,4.0,4.0,9.0,215.07888888888888\n",
      "2.091111111111111,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60.0,2.0,1.0,3.0,1.0,4.0,4.0,4.0,9.0,215.07888888888888\n",
      "2.807777777777778,,,,,,,,,,,,,,,,-1.0,,,,,,,,,,21.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,30.0,370.0,60.0,2.0,1.0,3.0,1.0,4.0,4.0,4.0,9.0,215.07888888888888\n",
      "3.4411111111111112,,,,,,,,,,,,,,,,-5.0,,,,,,,,,,22.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7.8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,43.0,170.0,60.0,2.0,1.0,3.0,1.0,4.0,4.0,4.0,9.0,215.07888888888888\n",
      "3.457777777777778,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,24.6,24.6,7.6,,,,,2.1,2.1,,,,,,,31.6,31.0,102.0,,,,,,,,,,,,,,,,,,,,,,,,22.4,41.8,41.8,,,,,,121.0,,,,22.4,17.7,,2.41,,,,,,,,,,,,,,,,,,,,,,8.8,,8.8,,,60.0,2.0,1.0,3.0,1.0,4.0,4.0,4.0,9.0,215.07888888888888\n"
     ]
    }
   ],
   "source": [
    "# Sample input data below\n",
    "#!head /home/ubuntu/duett/mimic-iv-benchmarks/data/in-hospital-mortality/test/19872834_episode1_timeseries.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c8cdc-a666-4d0a-b62d-a33b298ab7c6",
   "metadata": {},
   "source": [
    "Above columns fully compliant with paper's design. NOTE: This is before categorical one-hot encoding.\n",
    "\n",
    "Upon conducting a sanity check, the train and test sets for the ICU mortality task were found to **perfectly** replicate the figures stated in the paper. (Please note: when referring to \"instances,\" The paper is indicating individual patients, while \"samples\" denote valid episodes.)\n",
    "```\n",
    "For the ICU mortality task, our training set consists of a total of 19,699 instances\r",
    "with a positive mortality rate of 12.95%, our validation set contains 4,257 instances with a\r",
    "mortality rate of 13.55%, and our test set contains 4,245 instances with a mortality rate of\r",
    "12.39%.\n",
    "```\n",
    "\n",
    "#### Here's what I accomplished, with all code submitted to GitHub:\n",
    "\n",
    "    1. Adapted the code base to work with MIMIC-IV 2.0, building upon the existing code from MIMIC-III and MIMIC-IV 1.0.\n",
    "    2. Conducted feature engineering as per the guidelines outlined in the paper, incorporating 85 chart event variables and 29 lab event variables.\n",
    "    3. Ensured alignment with the filtering logic described.\n",
    "    4. Applied one-hot encoding to handle categorical variables appropriately.\n",
    "    5. Warped class MIMICIVDataset(Dataset) and class MIMICIVDataModule(pl.LightningDataModule) for PyTorch Lightening training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730afb3-cd9f-4ba7-8234-ccaa29ed92e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Manager\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class MIMICIVDataset(Dataset):\n",
    "    def __init__(self, data_dir, split_name, n_timesteps=32, use_temp_cache=False, **kwargs):\n",
    "        if split_name == 'val':\n",
    "            self.data_dir = os.path.join(data_dir, 'train')\n",
    "        else:\n",
    "            self.data_dir = os.path.join(data_dir, split_name)\n",
    "        self.split_name = split_name\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.temp_cache = Manager().dict() if use_temp_cache else None\n",
    "        self.train_prop = 0.7\n",
    "        self.val_prop = 0.15\n",
    "        self.X = self.y = None\n",
    "        self.predefined_categories = {\n",
    "            #\"Braden Activity\": set(range(1, 5)),\n",
    "            #\"Braden Friction/Shear\": set(range(1, 4)),\n",
    "            #\"Braden Mobility\": set(range(1, 5)),\n",
    "            #\"Braden Moisture\": set(range(1, 5)),\n",
    "            #\"Braden Nutrition\": set(range(1, 5)),\n",
    "            #\"Braden Sensory Perception\": set(range(1, 5)),\n",
    "            \"GCS - Eye Opening\": set(range(1, 5)),\n",
    "            \"GCS - Motor Response\": set(range(1, 7)),\n",
    "            \"GCS - Verbal Response\": set(range(0, 6)),  # Including \"No Response-ETT\" as 0\n",
    "            #\"Goal Richmond-RAS Scale\": set(range(-5, 1)),  # Negative and zero\n",
    "            #\"Pain Level\": set(range(0, 9)),  # Includes \"Unable to Score\"\n",
    "            #\"Pain Level Response\": set(range(0, 9)),  # Includes \"Unable to Score\"\n",
    "            #\"Richmond-RAS Scale\": set(range(-5, 5)),  # Negative through positive\n",
    "            #\"Strength L Arm\": set(range(0, 6)),\n",
    "            #\"Strength L Leg\": set(range(0, 6)),\n",
    "            #\"Strength R Arm\": set(range(0, 6)),\n",
    "            #\"Strength R Leg\": set(range(0, 6)),\n",
    "            #\"Ambulatory aid\": set(range(0, 8)),  # Including \"Furniture\" as 7\n",
    "            \"Capillary Refill L\": set(range(1, 3)),\n",
    "            \"Capillary Refill R\": set(range(1, 3)),\n",
    "            #\"Gait/Transferring\": set(range(1, 6)),\n",
    "            #\"History of falling (within 3 mnths)\": set(range(0, 2)),  # Yes or No\n",
    "            #\"IV/Saline lock\": set(range(0, 2)),  # Yes or No\n",
    "            \"Mental status\": set(range(1, 3)),\n",
    "            \"Marital Status\": set(range(1, 7)),  # Includes '' as 6\n",
    "            \"Insurance\": set(range(1, 6)),  # Includes '' as 5\n",
    "            \"Admission Location\": set(range(1, 14)),  # Includes '' as 13\n",
    "            \"Admission Type\": set(range(1, 12)),  # Includes '' as 11\n",
    "            \"Ethnicity\": set(range(0, 5)),  # Includes multiple ethnic groups and '' as 0\n",
    "            \"First Care Unit\": set(range(1, 12))  # Includes '' as 11\n",
    "        }\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        # Load the list of stays\n",
    "        listfile = os.path.join(self.data_dir, \"listfile.csv\")\n",
    "\n",
    "        stay_list = pd.read_csv(listfile)\n",
    "        # Randomly shuffle the DataFrame\n",
    "        stay_list = stay_list.sample(frac=1, random_state=2020)  # Use a seed for reproducibility\n",
    "\n",
    "        # Calculate split indices\n",
    "        num_stays = len(stay_list)\n",
    "        num_val = int(num_stays * self.val_prop / (self.val_prop + self.train_prop))  # First part for validation\n",
    "        num_train = num_stays - num_val  # Rest part for training\n",
    "\n",
    "        if self.split_name == 'val':\n",
    "            # Use the first part for validation\n",
    "            stay_list = stay_list.iloc[:num_val]\n",
    "        elif self.split_name == 'train':\n",
    "            # Use the rest part for training\n",
    "            stay_list = stay_list.iloc[num_val:num_stays]\n",
    "        else:\n",
    "            # If split_name is not 'train' or 'val', no slicing is needed\n",
    "            pass\n",
    "        #stay_list = stay_list.iloc[:1000]\n",
    "\n",
    "        timeseries_data = []\n",
    "        labels = []\n",
    "\n",
    "        # Load data for each stay\n",
    "        for _, row in tqdm(stay_list.iterrows(), total=stay_list.shape[0], desc=f'Loading {self.split_name} data'):\n",
    "            stay_id, label = row['stay'], row['y_true']\n",
    "            ts_filename = os.path.join(self.data_dir, stay_id)\n",
    "\n",
    "            # Read timeseries data\n",
    "            ts_data = pd.read_csv(ts_filename)\n",
    "            #ts_data = ts_data.iloc[:, :self.d_time_series_num()]\n",
    "            #pd.set_option('display.max_rows', None)\n",
    "            # print(ts_data.dtypes)\n",
    "            ts_data = ts_data.apply(pd.to_numeric, errors='coerce')\n",
    "            for column, categories in self.predefined_categories.items():\n",
    "                nan_category = -100\n",
    "                ts_data[column] = ts_data[column].fillna(nan_category).astype(int)\n",
    "\n",
    "                categories_with_nan = categories.union({nan_category})\n",
    "                ts_data[column] = pd.Categorical(ts_data[column], categories=categories_with_nan)\n",
    "\n",
    "                # Create dummy/one-hot encoded variables\n",
    "                dummies = pd.get_dummies(ts_data[column], prefix=column)\n",
    "\n",
    "                # Find the original column index\n",
    "                col_index = ts_data.columns.get_loc(column)\n",
    "\n",
    "                # Drop the original column\n",
    "                ts_data.drop(columns=[column], inplace=True)\n",
    "\n",
    "                # Concatenate data: part before the column, dummies, part after the column\n",
    "                first_part = ts_data.iloc[:, :col_index]\n",
    "                second_part = ts_data.iloc[:, col_index:]\n",
    "\n",
    "                # Concatenate all parts together\n",
    "                ts_data = pd.concat([first_part, dummies, second_part], axis=1)\n",
    "\n",
    "            #pd.set_option('display.max_rows', None)\n",
    "            #pd.set_option('display.max_columns', None)\n",
    "            #for col in ts_data.columns:\n",
    "            #    print(col)\n",
    "            #print(\"col len=\",len(ts_data.columns))\n",
    "            #exit(1)\n",
    "            # Store data\n",
    "            timeseries_data.append(torch.tensor(ts_data.values, dtype=torch.float32))\n",
    "            labels.append(label)\n",
    "\n",
    "        max_length = 1250\n",
    "        preprocessed_data = []\n",
    "        min_padding_length = 1250\n",
    "        # Pad sequences with NaN and store them\n",
    "        for ts_data in timeseries_data:\n",
    "            # Calculate how much padding is needed\n",
    "            padding_length = max_length - ts_data.shape[0]\n",
    "            if padding_length < min_padding_length:\n",
    "                min_padding_length = padding_length\n",
    "            # Pad the sequence with NaNs if necessary\n",
    "            if padding_length > 0:\n",
    "                padding = torch.full((padding_length, ts_data.shape[1]), float('nan'), dtype=torch.float32)\n",
    "                ts_data_padded = torch.cat((ts_data, padding), dim=0)\n",
    "            else:\n",
    "                ts_data_padded = ts_data\n",
    "\n",
    "            preprocessed_data.append(ts_data_padded)\n",
    "        print(f'max_length = 1250, min_padding_length={min_padding_length}')\n",
    "        # self.X = torch.stack(timeseries_data)\n",
    "        self.X = torch.stack(preprocessed_data)\n",
    "        self.y = torch.tensor(labels, dtype=torch.long).unsqueeze(1)\n",
    "\n",
    "        self.means = []\n",
    "        self.stds = []\n",
    "        self.maxes = []\n",
    "        self.mins = []\n",
    "        for i in range(self.X.shape[2]):\n",
    "            vals = self.X[:,:,i].flatten()\n",
    "            vals = vals[~torch.isnan(vals)]\n",
    "            if vals.numel() > 0:\n",
    "                self.means.append(vals.mean())\n",
    "                self.stds.append(vals.std())\n",
    "                self.maxes.append(vals.max())\n",
    "                self.mins.append(vals.min())\n",
    "            else:\n",
    "                self.means.append(0)\n",
    "                self.stds.append(1)\n",
    "                self.maxes.append(float('nan'))\n",
    "                self.mins.append(float('nan'))\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.temp_cache is not None and i in self.temp_cache:\n",
    "            return self.temp_cache[i]\n",
    "\n",
    "        ins = self.X[i, ~torch.isnan(self.X[i, :, 0]), :]\n",
    "        time = ins[:, 0] / 24  # input is HOURS\n",
    "        x_static = torch.zeros(self.d_static_num())\n",
    "\n",
    "        x_ts = torch.zeros((self.n_timesteps, self.d_time_series_num() * 2))\n",
    "        for i_t, t in enumerate(time):\n",
    "            bin = self.n_timesteps - 1 if t == time[-1] else int(t / time[-1] * self.n_timesteps)\n",
    "            for i_ts in range(1, self.d_time_series_num()+1):\n",
    "                x_i = ins[i_t, i_ts]\n",
    "                if not torch.isnan(x_i).item():\n",
    "                    x_ts[bin, i_ts - 1] = (x_i - self.means[i_ts]) / (self.stds[i_ts] + 1e-7)\n",
    "                    x_ts[bin, i_ts - 1 + self.d_time_series_num()] += 1\n",
    "        bin_ends = torch.arange(1, self.n_timesteps + 1) / self.n_timesteps * time[-1]\n",
    "\n",
    "        for i_tab in range(self.d_time_series_num()+1, self.d_time_series_num()+self.d_static_num()+1):\n",
    "            x_i = ins[0, i_tab]\n",
    "            x_i = (x_i - self.means[i_tab]) / (self.stds[i_tab] + 1e-7)\n",
    "            x_static[i_tab - self.d_time_series_num()-1] = x_i.nan_to_num(0.)\n",
    "\n",
    "        x = (x_ts, x_static, bin_ends)\n",
    "        y = self.y[i, 0]\n",
    "        if self.temp_cache is not None:\n",
    "            self.temp_cache[i] = (x, y)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def d_static_num(self):\n",
    "        return 61\n",
    "\n",
    "    def d_time_series_num(self):\n",
    "        return 161\n",
    "\n",
    "    def d_target(self):\n",
    "        return 1\n",
    "\n",
    "    def pos_frac(self):\n",
    "        return torch.mean(self.y.float()).item()\n",
    "\n",
    "def collate_into_seqs(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    return zip(*xs), ys\n",
    "class MIMICIVDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_path='./mimic-iv-benchmarks/data/in-hospital-mortality/', use_temp_cache=False, batch_size=8, num_workers=1, prefetch_factor=2,\n",
    "            verbose=0, **kwargs):\n",
    "        self.use_temp_cache = use_temp_cache\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.prefetch_factor = prefetch_factor\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.ds_train = MIMICIVDataset(self.data_path,'train', use_temp_cache=use_temp_cache)\n",
    "        self.ds_val = MIMICIVDataset(self.data_path,'val', use_temp_cache=use_temp_cache)\n",
    "        self.ds_test = MIMICIVDataset(self.data_path,'test', use_temp_cache=use_temp_cache)\n",
    "\n",
    "        self.prepare_data_per_node = False\n",
    "\n",
    "        self.dl_args = {'batch_size': self.batch_size, 'prefetch_factor': self.prefetch_factor,\n",
    "                        'collate_fn': collate_into_seqs, 'num_workers': num_workers}\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage is None:\n",
    "            self.ds_train.setup()\n",
    "            self.ds_val.setup()\n",
    "            self.ds_test.setup()\n",
    "        elif stage == 'fit':\n",
    "            self.ds_train.setup()\n",
    "            self.ds_val.setup()\n",
    "        elif stage == 'validate':\n",
    "            self.ds_val.setup()\n",
    "        elif stage == 'test':\n",
    "            self.ds_test.setup()\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def _log_hyperparams(self):\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds_train, shuffle=True, **self.dl_args)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds_val, **self.dl_args)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.ds_test, **self.dl_args)\n",
    "\n",
    "    def d_static_num(self):\n",
    "        return self.ds_train.d_static_num()\n",
    "\n",
    "    def d_time_series_num(self):\n",
    "        return self.ds_train.d_time_series_num()\n",
    "\n",
    "    def d_target(self):\n",
    "        return self.ds_train.d_target()\n",
    "\n",
    "    def pos_frac(self):\n",
    "        return self.ds_train.pos_frac()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219021ff-5fa0-410e-b54e-cb93d69024be",
   "metadata": {},
   "source": [
    "### PhysioNet-2012 Data: `torchtime.data.PhysioNet2012(self.split_name, train_prop=0.7, val_prop=0.15, time=False, seed=0)`\n",
    "\n",
    "### Time-series Binning Strategy: `Refer to paper 3.1 Data/Input Binning`\n",
    "  ```\n",
    "        x_ts = torch.zeros((self.n_timesteps, self.d_time_series_num()*2))\n",
    "        for i_t, t in enumerate(time):\n",
    "            bin = self.n_timesteps - 1 if t == time[-1] else int(t / time[-1] * self.n_timesteps)\n",
    "            for i_ts in range(1,37):\n",
    "                x_i = ins[i_t,i_ts]\n",
    "                if not torch.isnan(x_i).item():\n",
    "                    x_ts[bin, i_ts-1] = (x_i - self.means[i_ts])/(self.stds[i_ts] + 1e-7)\n",
    "                    x_ts[bin, i_ts-1+self.d_time_series_num()] += 1\n",
    "        bin_ends = torch.arange(1, self.n_timesteps+1) / self.n_timesteps * time[-1]\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1376193f-9566-4ccb-b88b-92ed8640f292",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Model Descriptions/Architecture:(quoted from paper)\n",
    "```\n",
    "The overall structure of our DuETT model is a series of DuETT layers followed by classification or self-supervised learning heads. Each DuETT layer is made up of two Transformer sublayers that attend along the event and time dimensions respectively. The first sublayer consists of multi-head attention over events followed by a feed-forward network operating along the event dimension, which can be collectively identified as an event transformer layer; the second sublayer consists of multi-head attention over time bins followed by a feed-forward network operating along the time dimension, the time transformer layer. The dual attention architecture enables our model to capture the two important modalities of EHR data, namely the types of events that are observed for a given patient and the times at which they are observed. Event-type and time bin embeddings are injected just before their respective sublayers. Embedding injections are done throughout the entire network, rather than just before the first layer, to ensure access and to emphasize the ordering information of data, especially in upper layers.\n",
    "```\n",
    "- **Layer Number/Size/Type**: DuETT model uses 2 DuETT layers, with a total of 4 Transformer sublayers. The Transformers have an internal feedforward dimension of 512. The classification head has one hidden layer of size 64 and batch normalization after the hidden layer. The static data encoder has one hidden layer of size 128 and batch normalization after the hidden layer. The implementation uses 32 time steps.\n",
    "\n",
    "  Below is the detailed breakdown of the actual layers and their respective number of parameters. Please note that minor discrepancies may arise depending on the treatment of certain columns as categorical, which could result in an expansion of the input dimensions.\n",
    "```\n",
    "   | Name                         | Type             | Params\n",
    "-------------------------------------------------------------------\n",
    "0  | special_embeddings           | Embedding        | 192   \n",
    "1  | embedding_layers             | ModuleList       | 302 K \n",
    "2  | n_obs_embedding              | Embedding        | 16    \n",
    "3  | event_transformers           | ModuleList       | 1.8 M \n",
    "4  | full_event_embedding         | Embedding        | 128 K \n",
    "5  | time_transformers            | ModuleList       | 8.7 M \n",
    "6  | full_time_embedding          | Sequential       | 245 K \n",
    "7  | full_rep_embedding           | Embedding        | 3.9 K \n",
    "8  | head                         | Sequential       | 249 K \n",
    "9  | pretrain_value_proj          | Sequential       | 626 K \n",
    "10 | pretrain_presence_proj       | Sequential       | 626 K \n",
    "11 | predict_events_proj          | Sequential       | 25.4 K\n",
    "12 | predict_events_presence_proj | Sequential       | 25.4 K\n",
    "13 | tab_encoder                  | Sequential       | 11.3 K\n",
    "14 | train_auroc                  | AUROC            | 0     \n",
    "15 | val_auroc                    | AUROC            | 0     \n",
    "16 | train_ap                     | AveragePrecision | 0     \n",
    "17 | val_ap                       | AveragePrecision | 0     \n",
    "18 | test_auroc                   | AUROC            | 0     \n",
    "19 | test_ap                      | AveragePrecision | 0     \n",
    "-------------------------------------------------------------------\n",
    "12.7 M    Trainable params\n",
    "0         Non-trainable params\n",
    "12.7 M    Total params\n",
    "50.953    Total estimated model params size (MB)\n",
    "```\n",
    "![](https://uiuc-dlh.s3.amazonaws.com/duett_arch.png)\n",
    "\n",
    "\n",
    "- **Activation Function**: The model employs activation functions such as ReLU or other non-linear functions to introduce non-linearity into the model, enabling it to capture complex patterns within the data.\n",
    "- **Training Objectives**:\n",
    "\n",
    "    - **Loss Function**: The training process involves a self-supervised learning (SSL) pre-training stage followed by a supervised fine-tuning stage. During SSL, the model is trained with pseudo-tasks that produce robust representations without the need for explicit labels. The loss function for pre-training includes both value and presence losses to capture the clinical priors and the sparsity structure of the EHR data.\n",
    "\n",
    "      ![](https://uiuc-dlh.s3.amazonaws.com/duett_loss.png)\n",
    "    - **Optimizer**: The model uses an optimizer like AdamW for stable and efficient training. The learning rate is scheduled with linear warmup followed by inverse square-root decay.\n",
    "    - **Weight of Each Loss Term**: The weights of each loss term are determined through hyperparameter tuning to balance the contributions of the value and presence predictions.\n",
    "\n",
    "- **Pretrained Model**: The DuETT model benefits from SSL pre-training, which allows it to learn useful representations from the data without relying on labeled data. This is particularly advantageous for EHR data where labeled samples may be scarce. It\r",
    "performs self-supervised pre-training for 300 epochs using AdamW.\n",
    "- **Fine tuning**: It fine-tune DuETT for 30 epochs for MIMIC-IV and 50 epochs for PhysioNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de756178-5a07-4931-a61a-b3d974277bfc",
   "metadata": {},
   "source": [
    "### Model Code\n",
    "\n",
    "[`duett.py`](https://github.com/layer6ai-labs/DuETT/blob/master/duett.py) by original author of paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81378af5-6b8d-479f-a4fe-00d2f12a262c",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Training Setup\n",
    "```\n",
    "1x A10 (24 GB PCIe)\n",
    "30 vCPUs, 200 GiB RAM, 1.4 TiB SSD\n",
    "```\n",
    "available on: [Lambda Labs](https://cloud.lambdalabs.com/)\n",
    "NOTE: Google Colab is not used. Classic Jupyter Notebook and terminal are used.\n",
    "\n",
    "**Total Cost(till Apr 14):~3500USD****\n",
    "\n",
    "\n",
    "### Training Code\n",
    "\n",
    "#### Training MIMIC-IV ICU Mortality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10364ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DuETT'...\n",
      "remote: Enumerating objects: 17, done.\u001b[K\n",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
      "remote: Total 17 (delta 6), reused 14 (delta 3), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (17/17), 1.55 MiB | 10.49 MiB/s, done.\n",
      "Resolving deltas: 100% (6/6), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['GITHUB_TOKEN'] = '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'  # Set this securely, perhaps in a configuration file or environment variable outside of the notebook\n",
    "\n",
    "# Use the token securely without exposing it in the notebook\n",
    "!git clone https://ryuiuc:${GITHUB_TOKEN}@github.com/ryuiuc/dlh-model DuETT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c570c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your current ipykernel is not on Python 3.9, do the below in a terminal first\n",
    "# > python3.9 -m venv DuETT/myenv\n",
    "# > source DuETT/myenv/bin/activate\n",
    "# > pip install ipykernel\n",
    "# > python -m ipykernel install --user --name=DuETT --display-name \"Python 3.9 (DuETT)\"\n",
    "# Then let Jupyter Notebook use the kernel named \"Python 3.9 (DuETT)\" before continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3fc2e-f918-4f84-ae31-334e22ec557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r DuETT/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18fb4960-5e87-4349-869b-dc6fabb3ca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is now: /home/ubuntu/duett/dlh_submission/DuETT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('DuETT')\n",
    "\n",
    "# Confirm the change\n",
    "print(\"Current working directory is now:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e069f9f-4b91-4386-8017-279043f98eeb",
   "metadata": {},
   "source": [
    "##### Download Pre-trained Model\n",
    "\n",
    "Pre-train code is at below which is commented out. \n",
    "\n",
    "Based on current pre-train progress, the best MIMIC-IV 2.0 ICU Mortality model is Epoch 149-Step 7650."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b977b495-b88d-4e71-8e19-1c6b6c7fec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-14 05:07:53--  https://uiuc-dlh.s3.amazonaws.com/epoch%3D149-step%3D7650.ckpt\n",
      "Resolving uiuc-dlh.s3.amazonaws.com (uiuc-dlh.s3.amazonaws.com)... 54.231.233.89, 54.231.129.161, 54.231.199.201, ...\n",
      "Connecting to uiuc-dlh.s3.amazonaws.com (uiuc-dlh.s3.amazonaws.com)|54.231.233.89|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 152379276 (145M) [binary/octet-stream]\n",
      "Saving to: ‘epoch=149-step=7650.ckpt’\n",
      "\n",
      "epoch=149-step=7650 100%[===================>] 145.32M  18.9MB/s    in 7.1s    \n",
      "\n",
      "2024-04-14 05:08:01 (20.5 MB/s) - ‘epoch=149-step=7650.ckpt’ saved [152379276/152379276]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://uiuc-dlh.s3.amazonaws.com/epoch%3D149-step%3D7650.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a334d-b539-44f2-b18e-ca8c60e3406f",
   "metadata": {},
   "source": [
    "##### Continue Fine-tuning and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bec9ddec-3f39-47e2-85cc-1071b9b08e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup: ignoring input\n",
      "Global seed set to 2020\n",
      "Loading train data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25820/25820 [15:41<00:00, 27.43it/s]\n",
      "max_length = 1250, min_padding_length=86\n",
      "Loading val data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5532/5532 [03:16<00:00, 28.09it/s]\n",
      "max_length = 1250, min_padding_length=20\n",
      "Loading test data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5547/5547 [03:17<00:00, 28.05it/s]\n",
      "Global seed set to 2020\n",
      "/home/ubuntu/duett/myenv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/myenv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "max_length = 1250, min_padding_length=365\n",
      "Loading from checkpoint\n",
      "warmup_steps 1000, base_lr None, invsqrt True, decay None\n",
      "Loading train data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25820/25820 [15:51<00:00, 27.13it/s]\n",
      "max_length = 1250, min_padding_length=86\n",
      "Loading val data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5532/5532 [03:19<00:00, 27.66it/s]\n",
      "/home/ubuntu/duett/myenv/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory checkpoints-mimiciv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/duett/myenv/lib/python3.9/site-packages/torch/optim/adamw.py:92: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(AdamW, self).__init__(params, defaults)\n",
      "\n",
      "   | Name                         | Type             | Params\n",
      "-------------------------------------------------------------------\n",
      "0  | special_embeddings           | Embedding        | 192   \n",
      "1  | embedding_layers             | ModuleList       | 302 K \n",
      "2  | n_obs_embedding              | Embedding        | 16    \n",
      "3  | event_transformers           | ModuleList       | 1.8 M \n",
      "4  | full_event_embedding         | Embedding        | 128 K \n",
      "5  | time_transformers            | ModuleList       | 8.7 M \n",
      "6  | full_time_embedding          | Sequential       | 245 K \n",
      "7  | full_rep_embedding           | Embedding        | 3.9 K \n",
      "8  | head                         | Sequential       | 249 K \n",
      "9  | pretrain_value_proj          | Sequential       | 626 K \n",
      "10 | pretrain_presence_proj       | Sequential       | 626 K \n",
      "11 | predict_events_proj          | Sequential       | 25.4 K\n",
      "12 | predict_events_presence_proj | Sequential       | 25.4 K\n",
      "13 | tab_encoder                  | Sequential       | 11.3 K\n",
      "14 | train_auroc                  | AUROC            | 0     \n",
      "15 | val_auroc                    | AUROC            | 0     \n",
      "16 | train_ap                     | AveragePrecision | 0     \n",
      "17 | val_ap                       | AveragePrecision | 0     \n",
      "18 | test_auroc                   | AUROC            | 0     \n",
      "19 | test_ap                      | AveragePrecision | 0     \n",
      "-------------------------------------------------------------------\n",
      "12.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.7 M    Total params\n",
      "50.953    Total estimated model params size (MB)\n",
      "max_length = 1250, min_padding_length=20\n",
      "Sanity Checking DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [02:20<00:00, 70.03s/it]val_auroc tensor(0.4166, device='cuda:0') val_ap tensor(0.1227, device='cuda:0')\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [06:43<00:00,  6.51s/it, loss=0.671, val_loss=0.608]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:13<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [13:33<00:00, 13.13s/it, loss=0.568, val_loss=0.608]val_auroc tensor(0.8285, device='cuda:0') val_ap tensor(0.4600, device='cuda:0')\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [13:33<00:00, 13.13s/it, loss=0.568, val_loss=0.509]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:15<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [20:34<00:00, 19.92s/it, loss=0.55, val_loss=0.509]val_auroc tensor(0.8381, device='cuda:0') val_ap tensor(0.4716, device='cuda:0')\n",
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [20:34<00:00, 19.92s/it, loss=0.55, val_loss=0.498]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [27:29<00:00, 26.60s/it, loss=0.537, val_loss=0.498]val_auroc tensor(0.8494, device='cuda:0') val_ap tensor(0.4920, device='cuda:0')\n",
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [27:29<00:00, 26.61s/it, loss=0.537, val_loss=0.487]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [34:21<00:00, 33.26s/it, loss=0.535, val_loss=0.487]val_auroc tensor(0.8494, device='cuda:0') val_ap tensor(0.4861, device='cuda:0')\n",
      "Epoch 4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [34:21<00:00, 33.26s/it, loss=0.535, val_loss=0.490]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [41:16<00:00, 39.94s/it, loss=0.514, val_loss=0.490]val_auroc tensor(0.8522, device='cuda:0') val_ap tensor(0.4837, device='cuda:0')\n",
      "Epoch 5: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [41:16<00:00, 39.94s/it, loss=0.514, val_loss=0.513]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:21<?, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [48:16<00:00, 46.71s/it, loss=0.498, val_loss=0.513]val_auroc tensor(0.8608, device='cuda:0') val_ap tensor(0.5235, device='cuda:0')\n",
      "Epoch 6: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [48:16<00:00, 46.72s/it, loss=0.498, val_loss=0.471]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [55:09<00:00, 53.38s/it, loss=0.488, val_loss=0.471]val_auroc tensor(0.8600, device='cuda:0') val_ap tensor(0.5252, device='cuda:0')\n",
      "Epoch 7: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [55:09<00:00, 53.38s/it, loss=0.488, val_loss=0.488]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:11<?, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:02:03<00:00, 60.06s/it, loss=0.471, val_loss=0.488]val_auroc tensor(0.8677, device='cuda:0') val_ap tensor(0.5240, device='cuda:0')\n",
      "Epoch 8: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:02:03<00:00, 60.06s/it, loss=0.471, val_loss=0.454]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:08:57<00:00, 66.73s/it, loss=0.461, val_loss=0.454]val_auroc tensor(0.8733, device='cuda:0') val_ap tensor(0.5415, device='cuda:0')\n",
      "Epoch 9: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:08:57<00:00, 66.73s/it, loss=0.461, val_loss=0.441]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:13<?, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:15:56<00:00, 73.49s/it, loss=0.46, val_loss=0.441]val_auroc tensor(0.8722, device='cuda:0') val_ap tensor(0.5343, device='cuda:0')\n",
      "Epoch 10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:15:56<00:00, 73.49s/it, loss=0.46, val_loss=0.447]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:14<?, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:22:58<00:00, 80.29s/it, loss=0.441, val_loss=0.447]val_auroc tensor(0.8746, device='cuda:0') val_ap tensor(0.5514, device='cuda:0')\n",
      "Epoch 11: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:22:58<00:00, 80.29s/it, loss=0.441, val_loss=0.455]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:29:46<00:00, 86.89s/it, loss=0.434, val_loss=0.455]val_auroc tensor(0.8731, device='cuda:0') val_ap tensor(0.5481, device='cuda:0')\n",
      "Epoch 12: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:29:46<00:00, 86.89s/it, loss=0.434, val_loss=0.447]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:11<?, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:36:43<00:00, 93.60s/it, loss=0.426, val_loss=0.447]val_auroc tensor(0.8739, device='cuda:0') val_ap tensor(0.5573, device='cuda:0')\n",
      "Epoch 13: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:36:43<00:00, 93.60s/it, loss=0.426, val_loss=0.444]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:13<?, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:43:35<00:00, 100.25s/it, loss=0.426, val_loss=0.444]val_auroc tensor(0.8763, device='cuda:0') val_ap tensor(0.5549, device='cuda:0')\n",
      "Epoch 14: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:43:35<00:00, 100.25s/it, loss=0.426, val_loss=0.456]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:50:33<00:00, 107.00s/it, loss=0.419, val_loss=0.456]val_auroc tensor(0.8739, device='cuda:0') val_ap tensor(0.5550, device='cuda:0')\n",
      "Epoch 15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:50:33<00:00, 107.00s/it, loss=0.419, val_loss=0.446]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:57:28<00:00, 113.68s/it, loss=0.41, val_loss=0.446]val_auroc tensor(0.8695, device='cuda:0') val_ap tensor(0.5502, device='cuda:0')\n",
      "Epoch 16: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [1:57:28<00:00, 113.68s/it, loss=0.41, val_loss=0.557]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:04:25<00:00, 120.41s/it, loss=0.407, val_loss=0.557]val_auroc tensor(0.8771, device='cuda:0') val_ap tensor(0.5634, device='cuda:0')\n",
      "Epoch 17: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:04:25<00:00, 120.41s/it, loss=0.407, val_loss=0.443]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:11:18<00:00, 127.08s/it, loss=0.401, val_loss=0.443]val_auroc tensor(0.8760, device='cuda:0') val_ap tensor(0.5623, device='cuda:0')\n",
      "Epoch 18: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:11:18<00:00, 127.08s/it, loss=0.401, val_loss=0.445]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:13<?, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:18:19<00:00, 133.86s/it, loss=0.396, val_loss=0.445]val_auroc tensor(0.8681, device='cuda:0') val_ap tensor(0.5453, device='cuda:0')\n",
      "Epoch 19: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:18:19<00:00, 133.86s/it, loss=0.396, val_loss=0.453]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:25:16<00:00, 140.59s/it, loss=0.402, val_loss=0.453]val_auroc tensor(0.8777, device='cuda:0') val_ap tensor(0.5692, device='cuda:0')\n",
      "Epoch 20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:25:16<00:00, 140.59s/it, loss=0.402, val_loss=0.440]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:32:10<00:00, 147.27s/it, loss=0.391, val_loss=0.440]val_auroc tensor(0.8673, device='cuda:0') val_ap tensor(0.5580, device='cuda:0')\n",
      "Epoch 21: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:32:10<00:00, 147.27s/it, loss=0.391, val_loss=0.455]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:39:07<00:00, 153.99s/it, loss=0.386, val_loss=0.455]val_auroc tensor(0.8784, device='cuda:0') val_ap tensor(0.5780, device='cuda:0')\n",
      "Epoch 22: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:39:07<00:00, 153.99s/it, loss=0.386, val_loss=0.446]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:16<?, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:46:05<00:00, 160.74s/it, loss=0.392, val_loss=0.446]val_auroc tensor(0.8775, device='cuda:0') val_ap tensor(0.5753, device='cuda:0')\n",
      "Epoch 23: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:46:05<00:00, 160.74s/it, loss=0.392, val_loss=0.448]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:11<?, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:52:57<00:00, 167.39s/it, loss=0.38, val_loss=0.448]val_auroc tensor(0.8775, device='cuda:0') val_ap tensor(0.5752, device='cuda:0')\n",
      "Epoch 24: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:52:57<00:00, 167.39s/it, loss=0.38, val_loss=0.456]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:59:53<00:00, 174.09s/it, loss=0.375, val_loss=0.456]val_auroc tensor(0.8814, device='cuda:0') val_ap tensor(0.5839, device='cuda:0')\n",
      "Epoch 25: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [2:59:53<00:00, 174.09s/it, loss=0.375, val_loss=0.440]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:12<?, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [3:06:46<00:00, 180.75s/it, loss=0.369, val_loss=0.440]val_auroc tensor(0.8770, device='cuda:0') val_ap tensor(0.5702, device='cuda:0')\n",
      "Epoch 26: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [3:06:46<00:00, 180.75s/it, loss=0.369, val_loss=0.465]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:13<?, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [3:13:36<00:00, 187.37s/it, loss=0.365, val_loss=0.465]val_auroc tensor(0.8785, device='cuda:0') val_ap tensor(0.5779, device='cuda:0')\n",
      "Epoch 27: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [3:13:36<00:00, 187.37s/it, loss=0.365, val_loss=0.449]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:13<?, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [3:20:31<00:00, 194.06s/it, loss=0.373, val_loss=0.449]val_auroc tensor(0.8720, device='cuda:0') val_ap tensor(0.5683, device='cuda:0')\n",
      "Epoch 28: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [3:20:31<00:00, 194.06s/it, loss=0.373, val_loss=0.449]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                                                                                                                                                    | 0/11 [02:13<?, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [3:27:26<00:00, 200.76s/it, loss=0.362, val_loss=0.449]val_auroc tensor(0.8767, device='cuda:0') val_ap tensor(0.5721, device='cuda:0')\n",
      "Epoch 29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [3:27:26<00:00, 200.76s/it, loss=0.362, val_loss=0.453]\n",
      "Epoch 29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [3:27:26<00:00, 200.76s/it, loss=0.362, val_loss=0.453]/home/ubuntu/duett/myenv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/myenv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading test data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5547/5547 [03:26<00:00, 26.89it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "max_length = 1250, min_padding_length=365\n",
      "Testing DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [02:12<00:00, 12.04s/it]\n",
      "──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_ap            0.5389033555984497\n",
      "       test_auroc           0.8587720990180969\n",
      "        test_loss           0.5029744141557028\n",
      "──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "import pytorch_lightning as pl\n",
    "import argparse\n",
    "\n",
    "import duett\n",
    "import mimiciv_mortality\n",
    "\n",
    "class WarmUpCallback(pl.callbacks.Callback):\n",
    "    def __init__(self, steps=1000, base_lr=None, invsqrt=True, decay=None):\n",
    "        print(f'warmup_steps {steps}, base_lr {base_lr}, invsqrt {invsqrt}, decay {decay}')\n",
    "        self.warmup_steps = steps\n",
    "        self.decay = decay if decay is not None else steps\n",
    "        self.base_lr = base_lr\n",
    "        self.invsqrt = invsqrt\n",
    "        self.state = {'steps': 0, 'base_lr': float(base_lr) if base_lr is not None else None}\n",
    "\n",
    "    def set_lr(self, optimizer, lr):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def on_train_batch_start(self, trainer, model, batch, batch_idx):\n",
    "        optimizers = model.optimizers()\n",
    "        if self.state['steps'] < self.warmup_steps:\n",
    "            if isinstance(optimizers, list):\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = [o.param_groups[0]['lr'] for o in optimizers]\n",
    "                for opt, base in zip(optimizers, self.state['base_lr']):\n",
    "                    self.set_lr(opt, self.state['steps'] / self.warmup_steps * base)\n",
    "            else:\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = optimizers.param_groups[0]['lr']\n",
    "                self.set_lr(optimizers, self.state['steps'] / self.warmup_steps * self.state['base_lr'])\n",
    "            self.state['steps'] += 1\n",
    "        elif self.invsqrt:\n",
    "            if isinstance(optimizers, list):\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = [o.param_groups[0]['lr'] for o in optimizers]\n",
    "                for opt, base in zip(optimizers, self.state['base_lr']):\n",
    "                    lr = base * (self.decay / (self.state['steps'] - self.warmup_steps + self.decay)) ** 0.5\n",
    "                    self.set_lr(opt, lr)\n",
    "            else:\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = optimizers.param_groups[0]['lr']\n",
    "                lr = self.state['base_lr'] * (self.decay / (self.state['steps'] - self.warmup_steps + self.decay)) ** 0.5\n",
    "                self.set_lr(optimizers, lr)\n",
    "            self.state['steps'] += 1\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.state.update(state_dict)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.state.copy()\n",
    "\n",
    "def average_models(models):\n",
    "    models = list(models)\n",
    "    n = len(models)\n",
    "    sds = [m.state_dict() for m in models]\n",
    "    averaged = {}\n",
    "    for k in sds[0]:\n",
    "        averaged[k] = sum(sd[k] for sd in sds) / n\n",
    "    models[0].load_state_dict(averaged)\n",
    "    return models[0]\n",
    "\n",
    "seed = 2020\n",
    "pl.seed_everything(seed)\n",
    "dm = mimiciv_mortality.MIMICIVDataModule(data_path='../../mimic-iv-benchmarks/data/in-hospital-mortality/', batch_size=512, num_workers=30, use_temp_cache=False)\n",
    "dm.setup()\n",
    "\n",
    "#pretrained_path = 'checkpoints-mimiciv/last.ckpt'\n",
    "#pretrain_model = duett.pretrain_model(d_static_num=dm.d_static_num(),\n",
    "#        d_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac(),\n",
    "#        seed=seed)\n",
    "#checkpoint = pl.callbacks.ModelCheckpoint(save_last=True, monitor='val_loss', mode='min', save_top_k=1, dirpath='checkpoints-mimiciv')\n",
    "#warmup = WarmUpCallback(steps=2000)\n",
    "#trainer = pl.Trainer(gpus=1, logger=False, num_sanity_val_steps=2, max_epochs=300, # TODO: change back to 300\n",
    "#                     gradient_clip_val=1.0, callbacks=[warmup, checkpoint],\n",
    "#                     resume_from_checkpoint=pretrained_path)\n",
    "#trainer.fit(pretrain_model, dm)\n",
    "\n",
    "#pretrained_path = checkpoint.best_model_path\n",
    "#print('best model path of pretraining:', pretrained_path)\n",
    "#del pretrain_model, trainer\n",
    "#gc.collect()\n",
    "pretrained_path = 'epoch=149-step=7650.ckpt'\n",
    "for seed in range(2020, 2021):\n",
    "    pl.seed_everything(seed)\n",
    "    fine_tune_model = duett.fine_tune_model(pretrained_path,\n",
    "                                            d_static_num=dm.d_static_num(),\n",
    "                                            d_time_series_num=dm.d_time_series_num(),\n",
    "                                            d_target=dm.d_target(),\n",
    "                                            pos_frac=dm.pos_frac(),\n",
    "                                            seed=seed)\n",
    "    checkpoint = pl.callbacks.ModelCheckpoint(save_top_k=5,\n",
    "                                               save_last=False,\n",
    "                                               mode='max',\n",
    "                                               monitor='val_ap',\n",
    "                                               dirpath='checkpoints-mimiciv')\n",
    "    warmup = WarmUpCallback(steps=1000)\n",
    "    trainer = pl.Trainer(gpus=1,\n",
    "                         logger=False,\n",
    "                         max_epochs=30, # TODO: change back to 30\n",
    "                         gradient_clip_val=1.0,\n",
    "                         callbacks=[warmup, checkpoint])\n",
    "    trainer.fit(fine_tune_model, dm)\n",
    "    final_model = average_models([duett.fine_tune_model(path,\n",
    "                                                        d_static_num=dm.d_static_num(),\n",
    "                                                        d_time_series_num=dm.d_time_series_num(),\n",
    "                                                        d_target=dm.d_target(),\n",
    "                                                        pos_frac=dm.pos_frac())\n",
    "                                  for path in checkpoint.best_k_models.keys()])\n",
    "    trainer.test(final_model, dataloaders=dm)\n",
    "    del fine_tune_model, trainer, final_model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc1f45-80ae-4fe0-8b3a-c042dae65a4e",
   "metadata": {},
   "source": [
    "#### Training PhysioNet-2012\n",
    "\n",
    "##### Download Pre-trained Model\n",
    "\n",
    "Pre-train code is at below which is commented out. \n",
    "\n",
    "Based on current pre-train progress, the best PhysioNet-2012 model is Epoch 235-Step 4012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36cc6983-f392-42df-8cad-2154eddfcb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-13 08:44:17--  https://uiuc-dlh.s3.amazonaws.com/physionet-best-pretrain-epoch%3D235-step%3D4012.ckpt\n",
      "Resolving uiuc-dlh.s3.amazonaws.com (uiuc-dlh.s3.amazonaws.com)... 52.217.197.217, 52.216.129.123, 3.5.25.221, ...\n",
      "Connecting to uiuc-dlh.s3.amazonaws.com (uiuc-dlh.s3.amazonaws.com)|52.217.197.217|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 48785659 (47M) [binary/octet-stream]\n",
      "Saving to: ‘physionet-best-pretrain-epoch=235-step=4012.ckpt’\n",
      "\n",
      "physionet-best-pret 100%[===================>]  46.53M  14.7MB/s    in 3.2s    \n",
      "\n",
      "2024-04-13 08:44:20 (14.7 MB/s) - ‘physionet-best-pretrain-epoch=235-step=4012.ckpt’ saved [48785659/48785659]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://uiuc-dlh.s3.amazonaws.com/physionet-best-pretrain-epoch%3D235-step%3D4012.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554dc042-d1ec-4fb0-9a62-41969b546519",
   "metadata": {},
   "source": [
    "##### Continue Fine-tuning and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9946ac58-eb41-473e-b30f-0ce78acbd057",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating cache...\n",
      "Validating cache...\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2020\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint\n",
      "warmup_steps 1000, base_lr None, invsqrt True, decay None\n",
      "Validating cache...\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torch/optim/adamw.py:92: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(AdamW, self).__init__(params, defaults)\n",
      "\n",
      "   | Name                         | Type             | Params\n",
      "-------------------------------------------------------------------\n",
      "0  | special_embeddings           | Embedding        | 192   \n",
      "1  | embedding_layers             | ModuleList       | 67.7 K\n",
      "2  | n_obs_embedding              | Embedding        | 16    \n",
      "3  | event_transformers           | ModuleList       | 1.8 M \n",
      "4  | full_event_embedding         | Embedding        | 29.3 K\n",
      "5  | time_transformers            | ModuleList       | 2.0 M \n",
      "6  | full_time_embedding          | Sequential       | 26.8 K\n",
      "7  | full_rep_embedding           | Embedding        | 888   \n",
      "8  | head                         | Sequential       | 57.1 K\n",
      "9  | pretrain_value_proj          | Sequential       | 32.0 K\n",
      "10 | pretrain_presence_proj       | Sequential       | 32.0 K\n",
      "11 | predict_events_proj          | Sequential       | 25.4 K\n",
      "12 | predict_events_presence_proj | Sequential       | 25.4 K\n",
      "13 | tab_encoder                  | Sequential       | 4.5 K \n",
      "14 | train_auroc                  | AUROC            | 0     \n",
      "15 | val_auroc                    | AUROC            | 0     \n",
      "16 | train_ap                     | AveragePrecision | 0     \n",
      "17 | val_ap                       | AveragePrecision | 0     \n",
      "18 | test_auroc                   | AUROC            | 0     \n",
      "19 | test_ap                      | AveragePrecision | 0     \n",
      "-------------------------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.279    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.4978, device='cuda:0') val_ap tensor(0.1556, device='cuda:0')\n",
      "val_auroc tensor(0.5335, device='cuda:0') val_ap tensor(0.1659, device='cuda:0')\n",
      "val_auroc tensor(0.6009, device='cuda:0') val_ap tensor(0.2029, device='cuda:0')\n",
      "val_auroc tensor(0.6966, device='cuda:0') val_ap tensor(0.2792, device='cuda:0')\n",
      "val_auroc tensor(0.7452, device='cuda:0') val_ap tensor(0.3362, device='cuda:0')\n",
      "val_auroc tensor(0.7763, device='cuda:0') val_ap tensor(0.3814, device='cuda:0')\n",
      "val_auroc tensor(0.7952, device='cuda:0') val_ap tensor(0.3995, device='cuda:0')\n",
      "val_auroc tensor(0.8143, device='cuda:0') val_ap tensor(0.4416, device='cuda:0')\n",
      "val_auroc tensor(0.8210, device='cuda:0') val_ap tensor(0.4404, device='cuda:0')\n",
      "val_auroc tensor(0.8287, device='cuda:0') val_ap tensor(0.4754, device='cuda:0')\n",
      "val_auroc tensor(0.8358, device='cuda:0') val_ap tensor(0.4882, device='cuda:0')\n",
      "val_auroc tensor(0.8445, device='cuda:0') val_ap tensor(0.5064, device='cuda:0')\n",
      "val_auroc tensor(0.8433, device='cuda:0') val_ap tensor(0.5025, device='cuda:0')\n",
      "val_auroc tensor(0.8491, device='cuda:0') val_ap tensor(0.5123, device='cuda:0')\n",
      "val_auroc tensor(0.8483, device='cuda:0') val_ap tensor(0.5122, device='cuda:0')\n",
      "val_auroc tensor(0.8520, device='cuda:0') val_ap tensor(0.5182, device='cuda:0')\n",
      "val_auroc tensor(0.8501, device='cuda:0') val_ap tensor(0.5244, device='cuda:0')\n",
      "val_auroc tensor(0.8504, device='cuda:0') val_ap tensor(0.5315, device='cuda:0')\n",
      "val_auroc tensor(0.8465, device='cuda:0') val_ap tensor(0.5221, device='cuda:0')\n",
      "val_auroc tensor(0.8526, device='cuda:0') val_ap tensor(0.5385, device='cuda:0')\n",
      "val_auroc tensor(0.8547, device='cuda:0') val_ap tensor(0.5382, device='cuda:0')\n",
      "val_auroc tensor(0.8557, device='cuda:0') val_ap tensor(0.5470, device='cuda:0')\n",
      "val_auroc tensor(0.8555, device='cuda:0') val_ap tensor(0.5457, device='cuda:0')\n",
      "val_auroc tensor(0.8555, device='cuda:0') val_ap tensor(0.5505, device='cuda:0')\n",
      "val_auroc tensor(0.8560, device='cuda:0') val_ap tensor(0.5439, device='cuda:0')\n",
      "val_auroc tensor(0.8589, device='cuda:0') val_ap tensor(0.5617, device='cuda:0')\n",
      "val_auroc tensor(0.8574, device='cuda:0') val_ap tensor(0.5570, device='cuda:0')\n",
      "val_auroc tensor(0.8547, device='cuda:0') val_ap tensor(0.5477, device='cuda:0')\n",
      "val_auroc tensor(0.8535, device='cuda:0') val_ap tensor(0.5444, device='cuda:0')\n",
      "val_auroc tensor(0.8561, device='cuda:0') val_ap tensor(0.5603, device='cuda:0')\n",
      "val_auroc tensor(0.8576, device='cuda:0') val_ap tensor(0.5512, device='cuda:0')\n",
      "val_auroc tensor(0.8585, device='cuda:0') val_ap tensor(0.5599, device='cuda:0')\n",
      "val_auroc tensor(0.8529, device='cuda:0') val_ap tensor(0.5522, device='cuda:0')\n",
      "val_auroc tensor(0.8580, device='cuda:0') val_ap tensor(0.5653, device='cuda:0')\n",
      "val_auroc tensor(0.8596, device='cuda:0') val_ap tensor(0.5604, device='cuda:0')\n",
      "val_auroc tensor(0.8535, device='cuda:0') val_ap tensor(0.5398, device='cuda:0')\n",
      "val_auroc tensor(0.8578, device='cuda:0') val_ap tensor(0.5518, device='cuda:0')\n",
      "val_auroc tensor(0.8263, device='cuda:0') val_ap tensor(0.5152, device='cuda:0')\n",
      "val_auroc tensor(0.8330, device='cuda:0') val_ap tensor(0.5166, device='cuda:0')\n",
      "val_auroc tensor(0.8468, device='cuda:0') val_ap tensor(0.5246, device='cuda:0')\n",
      "val_auroc tensor(0.8450, device='cuda:0') val_ap tensor(0.5326, device='cuda:0')\n",
      "val_auroc tensor(0.8501, device='cuda:0') val_ap tensor(0.5409, device='cuda:0')\n",
      "val_auroc tensor(0.8366, device='cuda:0') val_ap tensor(0.4961, device='cuda:0')\n",
      "val_auroc tensor(0.8541, device='cuda:0') val_ap tensor(0.5372, device='cuda:0')\n",
      "val_auroc tensor(0.8541, device='cuda:0') val_ap tensor(0.5477, device='cuda:0')\n",
      "val_auroc tensor(0.8330, device='cuda:0') val_ap tensor(0.5299, device='cuda:0')\n",
      "val_auroc tensor(0.8557, device='cuda:0') val_ap tensor(0.5505, device='cuda:0')\n",
      "val_auroc tensor(0.8519, device='cuda:0') val_ap tensor(0.5469, device='cuda:0')\n",
      "val_auroc tensor(0.8455, device='cuda:0') val_ap tensor(0.5395, device='cuda:0')\n",
      "val_auroc tensor(0.8554, device='cuda:0') val_ap tensor(0.5419, device='cuda:0')\n",
      "val_auroc tensor(0.8498, device='cuda:0') val_ap tensor(0.5303, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_ap            0.5473765134811401\n",
      "       test_auroc            0.869416356086731\n",
      "        test_loss           0.48961365012943475\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint\n",
      "warmup_steps 1000, base_lr None, invsqrt True, decay None\n",
      "Validating cache...\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torch/optim/adamw.py:92: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(AdamW, self).__init__(params, defaults)\n",
      "\n",
      "   | Name                         | Type             | Params\n",
      "-------------------------------------------------------------------\n",
      "0  | special_embeddings           | Embedding        | 192   \n",
      "1  | embedding_layers             | ModuleList       | 67.7 K\n",
      "2  | n_obs_embedding              | Embedding        | 16    \n",
      "3  | event_transformers           | ModuleList       | 1.8 M \n",
      "4  | full_event_embedding         | Embedding        | 29.3 K\n",
      "5  | time_transformers            | ModuleList       | 2.0 M \n",
      "6  | full_time_embedding          | Sequential       | 26.8 K\n",
      "7  | full_rep_embedding           | Embedding        | 888   \n",
      "8  | head                         | Sequential       | 57.1 K\n",
      "9  | pretrain_value_proj          | Sequential       | 32.0 K\n",
      "10 | pretrain_presence_proj       | Sequential       | 32.0 K\n",
      "11 | predict_events_proj          | Sequential       | 25.4 K\n",
      "12 | predict_events_presence_proj | Sequential       | 25.4 K\n",
      "13 | tab_encoder                  | Sequential       | 4.5 K \n",
      "14 | train_auroc                  | AUROC            | 0     \n",
      "15 | val_auroc                    | AUROC            | 0     \n",
      "16 | train_ap                     | AveragePrecision | 0     \n",
      "17 | val_ap                       | AveragePrecision | 0     \n",
      "18 | test_auroc                   | AUROC            | 0     \n",
      "19 | test_ap                      | AveragePrecision | 0     \n",
      "-------------------------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.279    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.4978, device='cuda:0') val_ap tensor(0.1556, device='cuda:0')\n",
      "val_auroc tensor(0.5340, device='cuda:0') val_ap tensor(0.1666, device='cuda:0')\n",
      "val_auroc tensor(0.6134, device='cuda:0') val_ap tensor(0.2129, device='cuda:0')\n",
      "val_auroc tensor(0.6920, device='cuda:0') val_ap tensor(0.2776, device='cuda:0')\n",
      "val_auroc tensor(0.7415, device='cuda:0') val_ap tensor(0.3287, device='cuda:0')\n",
      "val_auroc tensor(0.7696, device='cuda:0') val_ap tensor(0.3600, device='cuda:0')\n",
      "val_auroc tensor(0.7928, device='cuda:0') val_ap tensor(0.3872, device='cuda:0')\n",
      "val_auroc tensor(0.8027, device='cuda:0') val_ap tensor(0.4015, device='cuda:0')\n",
      "val_auroc tensor(0.8138, device='cuda:0') val_ap tensor(0.4246, device='cuda:0')\n",
      "val_auroc tensor(0.8204, device='cuda:0') val_ap tensor(0.4387, device='cuda:0')\n",
      "val_auroc tensor(0.8375, device='cuda:0') val_ap tensor(0.4823, device='cuda:0')\n",
      "val_auroc tensor(0.8404, device='cuda:0') val_ap tensor(0.4870, device='cuda:0')\n",
      "val_auroc tensor(0.8452, device='cuda:0') val_ap tensor(0.4934, device='cuda:0')\n",
      "val_auroc tensor(0.8354, device='cuda:0') val_ap tensor(0.4707, device='cuda:0')\n",
      "val_auroc tensor(0.8537, device='cuda:0') val_ap tensor(0.5162, device='cuda:0')\n",
      "val_auroc tensor(0.8441, device='cuda:0') val_ap tensor(0.5045, device='cuda:0')\n",
      "val_auroc tensor(0.8506, device='cuda:0') val_ap tensor(0.5289, device='cuda:0')\n",
      "val_auroc tensor(0.8544, device='cuda:0') val_ap tensor(0.5405, device='cuda:0')\n",
      "val_auroc tensor(0.8571, device='cuda:0') val_ap tensor(0.5332, device='cuda:0')\n",
      "val_auroc tensor(0.8512, device='cuda:0') val_ap tensor(0.5330, device='cuda:0')\n",
      "val_auroc tensor(0.8539, device='cuda:0') val_ap tensor(0.5378, device='cuda:0')\n",
      "val_auroc tensor(0.8548, device='cuda:0') val_ap tensor(0.5400, device='cuda:0')\n",
      "val_auroc tensor(0.8577, device='cuda:0') val_ap tensor(0.5552, device='cuda:0')\n",
      "val_auroc tensor(0.8542, device='cuda:0') val_ap tensor(0.5478, device='cuda:0')\n",
      "val_auroc tensor(0.8534, device='cuda:0') val_ap tensor(0.5506, device='cuda:0')\n",
      "val_auroc tensor(0.8513, device='cuda:0') val_ap tensor(0.5642, device='cuda:0')\n",
      "val_auroc tensor(0.8522, device='cuda:0') val_ap tensor(0.5534, device='cuda:0')\n",
      "val_auroc tensor(0.8582, device='cuda:0') val_ap tensor(0.5661, device='cuda:0')\n",
      "val_auroc tensor(0.8550, device='cuda:0') val_ap tensor(0.5483, device='cuda:0')\n",
      "val_auroc tensor(0.8576, device='cuda:0') val_ap tensor(0.5688, device='cuda:0')\n",
      "val_auroc tensor(0.8596, device='cuda:0') val_ap tensor(0.5538, device='cuda:0')\n",
      "val_auroc tensor(0.8591, device='cuda:0') val_ap tensor(0.5614, device='cuda:0')\n",
      "val_auroc tensor(0.8582, device='cuda:0') val_ap tensor(0.5681, device='cuda:0')\n",
      "val_auroc tensor(0.8586, device='cuda:0') val_ap tensor(0.5652, device='cuda:0')\n",
      "val_auroc tensor(0.8613, device='cuda:0') val_ap tensor(0.5653, device='cuda:0')\n",
      "val_auroc tensor(0.8605, device='cuda:0') val_ap tensor(0.5695, device='cuda:0')\n",
      "val_auroc tensor(0.8660, device='cuda:0') val_ap tensor(0.5691, device='cuda:0')\n",
      "val_auroc tensor(0.8562, device='cuda:0') val_ap tensor(0.5382, device='cuda:0')\n",
      "val_auroc tensor(0.8595, device='cuda:0') val_ap tensor(0.5476, device='cuda:0')\n",
      "val_auroc tensor(0.8586, device='cuda:0') val_ap tensor(0.5601, device='cuda:0')\n",
      "val_auroc tensor(0.8618, device='cuda:0') val_ap tensor(0.5596, device='cuda:0')\n",
      "val_auroc tensor(0.8524, device='cuda:0') val_ap tensor(0.5445, device='cuda:0')\n",
      "val_auroc tensor(0.8525, device='cuda:0') val_ap tensor(0.5485, device='cuda:0')\n",
      "val_auroc tensor(0.8580, device='cuda:0') val_ap tensor(0.5776, device='cuda:0')\n",
      "val_auroc tensor(0.8547, device='cuda:0') val_ap tensor(0.5660, device='cuda:0')\n",
      "val_auroc tensor(0.8397, device='cuda:0') val_ap tensor(0.4770, device='cuda:0')\n",
      "val_auroc tensor(0.8490, device='cuda:0') val_ap tensor(0.5504, device='cuda:0')\n",
      "val_auroc tensor(0.8595, device='cuda:0') val_ap tensor(0.5584, device='cuda:0')\n",
      "val_auroc tensor(0.8569, device='cuda:0') val_ap tensor(0.5657, device='cuda:0')\n",
      "val_auroc tensor(0.8480, device='cuda:0') val_ap tensor(0.5482, device='cuda:0')\n",
      "val_auroc tensor(0.8548, device='cuda:0') val_ap tensor(0.5603, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_ap             0.564518928527832\n",
      "       test_auroc           0.8703322410583496\n",
      "        test_loss           0.46560638726343934\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=0)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint\n",
      "warmup_steps 1000, base_lr None, invsqrt True, decay None\n",
      "Validating cache...\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torch/optim/adamw.py:92: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(AdamW, self).__init__(params, defaults)\n",
      "\n",
      "   | Name                         | Type             | Params\n",
      "-------------------------------------------------------------------\n",
      "0  | special_embeddings           | Embedding        | 192   \n",
      "1  | embedding_layers             | ModuleList       | 67.7 K\n",
      "2  | n_obs_embedding              | Embedding        | 16    \n",
      "3  | event_transformers           | ModuleList       | 1.8 M \n",
      "4  | full_event_embedding         | Embedding        | 29.3 K\n",
      "5  | time_transformers            | ModuleList       | 2.0 M \n",
      "6  | full_time_embedding          | Sequential       | 26.8 K\n",
      "7  | full_rep_embedding           | Embedding        | 888   \n",
      "8  | head                         | Sequential       | 57.1 K\n",
      "9  | pretrain_value_proj          | Sequential       | 32.0 K\n",
      "10 | pretrain_presence_proj       | Sequential       | 32.0 K\n",
      "11 | predict_events_proj          | Sequential       | 25.4 K\n",
      "12 | predict_events_presence_proj | Sequential       | 25.4 K\n",
      "13 | tab_encoder                  | Sequential       | 4.5 K \n",
      "14 | train_auroc                  | AUROC            | 0     \n",
      "15 | val_auroc                    | AUROC            | 0     \n",
      "16 | train_ap                     | AveragePrecision | 0     \n",
      "17 | val_ap                       | AveragePrecision | 0     \n",
      "18 | test_auroc                   | AUROC            | 0     \n",
      "19 | test_ap                      | AveragePrecision | 0     \n",
      "-------------------------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.279    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auroc tensor(0.4978, device='cuda:0') val_ap tensor(0.1556, device='cuda:0')\n",
      "val_auroc tensor(0.5371, device='cuda:0') val_ap tensor(0.1680, device='cuda:0')\n",
      "val_auroc tensor(0.6192, device='cuda:0') val_ap tensor(0.2141, device='cuda:0')\n",
      "val_auroc tensor(0.6911, device='cuda:0') val_ap tensor(0.2726, device='cuda:0')\n",
      "val_auroc tensor(0.7511, device='cuda:0') val_ap tensor(0.3421, device='cuda:0')\n",
      "val_auroc tensor(0.7776, device='cuda:0') val_ap tensor(0.3757, device='cuda:0')\n",
      "val_auroc tensor(0.7938, device='cuda:0') val_ap tensor(0.3904, device='cuda:0')\n",
      "val_auroc tensor(0.8117, device='cuda:0') val_ap tensor(0.4197, device='cuda:0')\n",
      "val_auroc tensor(0.8180, device='cuda:0') val_ap tensor(0.4454, device='cuda:0')\n",
      "val_auroc tensor(0.8266, device='cuda:0') val_ap tensor(0.4508, device='cuda:0')\n",
      "val_auroc tensor(0.8300, device='cuda:0') val_ap tensor(0.4690, device='cuda:0')\n",
      "val_auroc tensor(0.8432, device='cuda:0') val_ap tensor(0.4900, device='cuda:0')\n",
      "val_auroc tensor(0.8498, device='cuda:0') val_ap tensor(0.5070, device='cuda:0')\n",
      "val_auroc tensor(0.8427, device='cuda:0') val_ap tensor(0.5092, device='cuda:0')\n",
      "val_auroc tensor(0.8521, device='cuda:0') val_ap tensor(0.5191, device='cuda:0')\n",
      "val_auroc tensor(0.8515, device='cuda:0') val_ap tensor(0.5246, device='cuda:0')\n",
      "val_auroc tensor(0.8551, device='cuda:0') val_ap tensor(0.5307, device='cuda:0')\n",
      "val_auroc tensor(0.8513, device='cuda:0') val_ap tensor(0.5302, device='cuda:0')\n",
      "val_auroc tensor(0.8550, device='cuda:0') val_ap tensor(0.5364, device='cuda:0')\n",
      "val_auroc tensor(0.8533, device='cuda:0') val_ap tensor(0.5326, device='cuda:0')\n",
      "val_auroc tensor(0.8531, device='cuda:0') val_ap tensor(0.5309, device='cuda:0')\n",
      "val_auroc tensor(0.8544, device='cuda:0') val_ap tensor(0.5311, device='cuda:0')\n",
      "val_auroc tensor(0.8557, device='cuda:0') val_ap tensor(0.5475, device='cuda:0')\n",
      "val_auroc tensor(0.8488, device='cuda:0') val_ap tensor(0.5364, device='cuda:0')\n",
      "val_auroc tensor(0.8521, device='cuda:0') val_ap tensor(0.5407, device='cuda:0')\n",
      "val_auroc tensor(0.8537, device='cuda:0') val_ap tensor(0.5398, device='cuda:0')\n",
      "val_auroc tensor(0.8521, device='cuda:0') val_ap tensor(0.5374, device='cuda:0')\n",
      "val_auroc tensor(0.8535, device='cuda:0') val_ap tensor(0.5240, device='cuda:0')\n",
      "val_auroc tensor(0.8437, device='cuda:0') val_ap tensor(0.5320, device='cuda:0')\n",
      "val_auroc tensor(0.8444, device='cuda:0') val_ap tensor(0.5119, device='cuda:0')\n",
      "val_auroc tensor(0.8522, device='cuda:0') val_ap tensor(0.5306, device='cuda:0')\n",
      "val_auroc tensor(0.8514, device='cuda:0') val_ap tensor(0.5331, device='cuda:0')\n",
      "val_auroc tensor(0.8584, device='cuda:0') val_ap tensor(0.5647, device='cuda:0')\n",
      "val_auroc tensor(0.8574, device='cuda:0') val_ap tensor(0.5573, device='cuda:0')\n",
      "val_auroc tensor(0.8585, device='cuda:0') val_ap tensor(0.5451, device='cuda:0')\n",
      "val_auroc tensor(0.8510, device='cuda:0') val_ap tensor(0.5478, device='cuda:0')\n",
      "val_auroc tensor(0.8532, device='cuda:0') val_ap tensor(0.5538, device='cuda:0')\n",
      "val_auroc tensor(0.8550, device='cuda:0') val_ap tensor(0.5458, device='cuda:0')\n",
      "val_auroc tensor(0.8585, device='cuda:0') val_ap tensor(0.5572, device='cuda:0')\n",
      "val_auroc tensor(0.8556, device='cuda:0') val_ap tensor(0.5636, device='cuda:0')\n",
      "val_auroc tensor(0.8572, device='cuda:0') val_ap tensor(0.5479, device='cuda:0')\n",
      "val_auroc tensor(0.8556, device='cuda:0') val_ap tensor(0.5550, device='cuda:0')\n",
      "val_auroc tensor(0.8629, device='cuda:0') val_ap tensor(0.5739, device='cuda:0')\n",
      "val_auroc tensor(0.8610, device='cuda:0') val_ap tensor(0.5674, device='cuda:0')\n",
      "val_auroc tensor(0.8523, device='cuda:0') val_ap tensor(0.5589, device='cuda:0')\n",
      "val_auroc tensor(0.8576, device='cuda:0') val_ap tensor(0.5585, device='cuda:0')\n",
      "val_auroc tensor(0.8138, device='cuda:0') val_ap tensor(0.4737, device='cuda:0')\n",
      "val_auroc tensor(0.8584, device='cuda:0') val_ap tensor(0.5632, device='cuda:0')\n",
      "val_auroc tensor(0.8481, device='cuda:0') val_ap tensor(0.5383, device='cuda:0')\n",
      "val_auroc tensor(0.8500, device='cuda:0') val_ap tensor(0.5468, device='cuda:0')\n",
      "val_auroc tensor(0.8582, device='cuda:0') val_ap tensor(0.5671, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/duett/dlh_submission/DuETT/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Loading from checkpoint\n",
      "Validating cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_ap            0.5617507100105286\n",
      "       test_auroc            0.869026780128479\n",
      "        test_loss           0.47735832650971227\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "import pytorch_lightning as pl\n",
    "import argparse\n",
    "\n",
    "import duett\n",
    "import physionet\n",
    "\n",
    "class WarmUpCallback(pl.callbacks.Callback):\n",
    "    \"\"\"Linear warmup over warmup_steps batches, tries to auto-detect the base lr\"\"\"\n",
    "    def __init__(self, steps=1000, base_lr=None, invsqrt=True, decay=None):\n",
    "        print('warmup_steps {}, base_lr {}, invsqrt {}, decay {}'.format(steps, base_lr, invsqrt, decay))\n",
    "        self.warmup_steps = steps\n",
    "        if decay is None:\n",
    "            self.decay = steps\n",
    "        else:\n",
    "            self.decay = decay\n",
    "\n",
    "        if base_lr is None:\n",
    "            self.state = {'steps': 0, 'base_lr': base_lr}\n",
    "        else:\n",
    "            self.state = {'steps': 0, 'base_lr': float(base_lr)}\n",
    "\n",
    "        self.invsqrt = invsqrt\n",
    "\n",
    "    def set_lr(self, optimizer, lr):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def on_train_batch_start(self, trainer, model, batch, batch_idx):\n",
    "        optimizers = model.optimizers()\n",
    "\n",
    "        if self.state['steps'] < self.warmup_steps:\n",
    "            if type(optimizers) == 'list':\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = [o.param_groups[0]['lr'] for o in optimizers]\n",
    "                for opt,base in zip(optimizers, self.state['base_lr']):\n",
    "                    self.set_lr(opt, self.state['steps']/self.warmup_steps * base)\n",
    "            else:\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = optimizers.param_groups[0]['lr']\n",
    "                self.set_lr(optimizers, self.state['steps']/self.warmup_steps * self.state['base_lr'])\n",
    "            self.state['steps'] += 1\n",
    "        elif self.invsqrt:\n",
    "            if type(optimizers) == 'list':\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = [o.param_groups[0]['lr'] for o in optimizers]\n",
    "                for opt,base in zip(optimizers, self.state['base_lr']):\n",
    "                    self.set_lr(opt,base * (self.decay / (self.state['steps'] - self.warmup_steps + self.decay)) ** 0.5)\n",
    "            else:\n",
    "                if self.state['base_lr'] is None:\n",
    "                    self.state['base_lr'] = optimizers.param_groups[0]['lr']\n",
    "                self.set_lr(optimizers, self.state['base_lr'] * (\n",
    "                            self.decay / (self.state['steps'] - self.warmup_steps + self.decay)) ** 0.5)\n",
    "            self.state['steps'] += 1\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.state.update(state_dict)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.state.copy()\n",
    "\n",
    "def average_models(models):\n",
    "    \"\"\"Averages model weights and loads the resulting weights into the first model, returning it\"\"\"\n",
    "    models = list(models)\n",
    "    n = len(models)\n",
    "    sds = [m.state_dict() for m in models]\n",
    "    averaged = {}\n",
    "    for k in sds[0]:\n",
    "        averaged[k] = sum(sd[k] for sd in sds) / n\n",
    "    models[0].load_state_dict(averaged)\n",
    "    return models[0]\n",
    "\n",
    "seed = 2020\n",
    "pl.seed_everything(seed)\n",
    "dm = physionet.PhysioNetDataModule(batch_size=512, num_workers=30, use_temp_cache=True)\n",
    "dm.setup()\n",
    "#pretrain_model = duett.pretrain_model(d_static_num=dm.d_static_num(),\n",
    "#        d_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac(),\n",
    "#        seed=seed)\n",
    "#checkpoint = pl.callbacks.ModelCheckpoint(save_last=True, monitor='val_loss', mode='min', save_top_k=1, dirpath='checkpoints')\n",
    "#warmup = WarmUpCallback(steps=2000)\n",
    "#trainer = pl.Trainer(gpus=1, logger=False, num_sanity_val_steps=2, max_epochs=300,\n",
    "#        gradient_clip_val=1.0, callbacks=[warmup, checkpoint])\n",
    "#trainer.fit(pretrain_model, dm)\n",
    "\n",
    "pretrained_path = \"physionet-best-pretrain-epoch=235-step=4012.ckpt\"\n",
    "for seed in range(2020, 2023):\n",
    "    pl.seed_everything(seed)\n",
    "    fine_tune_model = duett.fine_tune_model(pretrained_path, d_static_num=dm.d_static_num(),\n",
    "            d_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac(), seed=seed)\n",
    "    checkpoint = pl.callbacks.ModelCheckpoint(save_top_k=5, save_last=False, mode='max', monitor='val_ap', dirpath='checkpoints')\n",
    "    warmup = WarmUpCallback(steps=1000)\n",
    "    trainer = pl.Trainer(gpus=1, logger=False, max_epochs=50, gradient_clip_val=1.0,\n",
    "            callbacks=[warmup, checkpoint], progress_bar_refresh_rate=0, log_every_n_steps=100)\n",
    "    trainer.fit(fine_tune_model, dm)\n",
    "    final_model = average_models([duett.fine_tune_model(path, d_static_num=dm.d_static_num(),\n",
    "            d_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac())\n",
    "            for path in checkpoint.best_k_models.keys()])\n",
    "    trainer.test(final_model, dataloaders=dm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a685195a-0552-4790-8c99-b20777fcdb08",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "1. Metrics descriptions\n",
    "- Average Precision: This metric calculates the mean precision of the model at different recall levels by summarizing the precision-recall curve.\n",
    "- AUROC: AUROC measures the likelihood that the model ranks a randomly chosen positive instance higher than a randomly chosen negative one across all possible thresholds.\n",
    "- Average Loss: Average Loss quantifies the model’s mean prediction error across all samples, providing an overall measure of its performance.\n",
    "   \n",
    "2. Implementation code (embeded in above training code segment)\n",
    "\n",
    "- Helper function:\n",
    "```\n",
    "def average_models(models):\n",
    "    \"\"\"Averages model weights and loads the resulting weights into the first model, returning it\"\"\"\n",
    "    models = list(models)\n",
    "    n = len(models)\n",
    "    sds = [m.state_dict() for m in models]\n",
    "    averaged = {}\n",
    "    for k in sds[0]:\n",
    "        averaged[k] = sum(sd[k] for sd in sds) / n\n",
    "    models[0].load_state_dict(averaged)\n",
    "    return models[0]\n",
    "```\n",
    "- Average of top 5 during fine-tuning\n",
    "```\n",
    "final_model = average_models([duett.fine_tune_model(path, d_static_num=dm.d_static_num(),\n",
    "            d_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac())\n",
    "            for path in checkpoint.best_k_models.keys()])\n",
    "    trainer.test(final_model, dataloaders=dm)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b520e-ade2-4542-8457-6c38928c717b",
   "metadata": {},
   "source": [
    "# Results\n",
    "## 1. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf7a74-0394-4511-a098-cae3084584f9",
   "metadata": {},
   "source": [
    "### MIMIC-IV 2.0 ICU Mortality - Approaching Paper Benchmark\n",
    "(Fine-tuned from pre-training Epoch 149 only, pre-training is half done due to limited GPU capability)\n",
    "```\n",
    "    test_ap             0.5389033555984497\n",
    "    test_auroc          0.8587720990180969\n",
    "    test_loss           0.5029744141557028\n",
    "```\n",
    "VS.\n",
    "\n",
    "![](https://uiuc-dlh.s3.amazonaws.com/duett_paper_mimic_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a694bf67-70b4-479b-9d25-d18563f3c681",
   "metadata": {},
   "source": [
    "### PhysioNet-2012 Mortality - Hit Paper Benchmark\n",
    "```\n",
    "(Seed 2021)\n",
    "    test_ap             0.564518928527832\n",
    "    test_auroc          0.8703322410583496\n",
    "    test_loss           0.46560638726343934\n",
    "```\n",
    "VS.\n",
    "\n",
    "![](https://uiuc-dlh.s3.amazonaws.com/duett_paper_physio_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7ebd10-77cb-48fa-9c5c-c4766f0e688e",
   "metadata": {},
   "source": [
    "## 2. Analysis\n",
    "- The results for the PhysioNet-2012 dataset have been successfully replicated without any inconsistencies.\n",
    "- Due to budget constraints and the limited capacity of the GPU setup, the large MIMIC-IV dataset requires additional training time to achieve optimal results, as the current progress is still on track to match the best outcomes.\n",
    "- The MIMIC-IV ICU Mortality task has seen significant improvement due to careful feature engineering. The AUROC has increased from 0.82 to 0.858 as I have progressively implemented and corrected further details in accordance with the paper and my own discoveries.\n",
    "- For the MIMIC-IV ICU Mortality task, focusing on feature engineering and hyperparameter tuning (both are not fully disclosed in original paper) is key to refining the model's performance, assuming that the model implementation from the paper is accurate.\n",
    "## 3. Plan\n",
    "- Continue with pre-training on the MIMIC-IV dataset and will update the model with the best parameters to proceed with fine-tuning and testing.Persist with pre-training on the MIMIC-IV dataset and will update the model with the best parameters to proceed with fine-tuning and testing.\n",
    "- Continue with ablation tests; however, these plans may be subject to change depending on the increasing budgetary demands.with ablation tests; however, these plans may be subject to change depending on the increasing budgetary demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7f695-d2a8-4243-9eca-be461795577c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (DuETT)",
   "language": "python",
   "name": "duett"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
